name: exist2025_env
channels:
  - defaults
  - conda-forge
dependencies:
  - python=3.11.13
  - pip=25.1
  - ipykernel=6.30.1
  - ipython=9.5.0
  - jupyter_client=8.6.3
  - jupyter_core=5.8.1
  - matplotlib=3.10.0
  - matplotlib-inline=0.1.7
  - numpy=2.3.2
  - pandas=2.2.3
  - scikit-learn=1.7.1
  - seaborn=0.13.2
  - tqdm=4.67.1
  - transformers=4.49.0
  - tokenizers=0.22.0
  - sentencepiece=0.2.0
  - safetensors=0.5.3
  - torch=2.7.1  # Cambia a +cu118 si usas GPU CUDA, o cpu si solo CPU
  - torchvision=0.22.1  # Cambia a +cu118 si usas GPU CUDA
  - torchaudio=2.7.1  # Cambia a +cu118 si usas GPU CUDA
  - fastembed
  - onnxruntime=1.22.1
  - pip:
      - accelerate==1.10.1
      - aiohappyeyeballs==2.6.1
      - aiohttp==3.12.15
      - aiosignal==1.4.0
      - aiosqlite==0.21.0
      - annotated-types==0.7.0
      - anyio==4.10.0
      - attrs==25.3.0
      - banks==2.2.0
      - beautifulsoup4==4.13.5
      - certifi==2025.8.3
      - charset-normalizer==3.4.3
      - click==8.2.1
      - colorama==0.4.6
      - coloredlogs==15.0.1
      - dataclasses-json==0.6.7
      - defusedxml==0.7.1
      - deprecated==1.2.18
      - dirtyjson==1.0.8
      - distro==1.9.0
      - editorconfig==0.17.1
      - evaluate==0.4.5
      - fastembed==0.7.3
      - filelock==3.19.1
      - filetype==1.2.0
      - flatbuffers==25.2.10
      - frozenlist==1.7.0
      - fsspec==2025.7.0
      - greenlet==3.2.4
      - griffe==1.13.0
      - grpcio==1.74.0
      - grpcio-tools==1.74.0
      - h11==0.16.0
      - h2==4.3.0
      - hf-xet==1.1.9
      - hpack==4.1.0
      - httpcore==1.0.9
      - httpx==0.28.1
      - huggingface-hub==0.34.4
      - humanfriendly==10.0
      - hyperframe==6.1.0
      - idna==3.10
      - iniconfig==2.1.0
      - jinja2==3.1.6
      - jiter==0.10.0
      - joblib==1.5.2
      - jsbeautifier==1.14.9
      - jsonschema==4.23.0
      - jsonschema-specifications==2025.4.1
      - llama-cloud==0.1.35
      - llama-cloud-services==0.6.54
      - llama-index==0.13.3
      - llama-index-cli==0.5.0
      - llama-index-core==0.13.3
      - llama-index-embeddings-fastembed==0.4.0
      - llama-index-embeddings-ollama==0.8.2
      - llama-index-embeddings-openai==0.5.0
      - llama-index-indices-managed-llama-cloud==0.9.2
      - llama-index-instrumentation==0.4.0
      - llama-index-llms-ollama==0.7.1
      - llama-index-llms-openai==0.5.4
      - llama-index-readers-file==0.5.2
      - llama-index-readers-llama-parse==0.5.0
      - llama-index-vector-stores-qdrant==0.8.2
      - llama-index-workflows==1.3.0
      - llama-parse==0.6.54
      - loguru==0.7.3
      - markupsafe==3.0.2
      - marshmallow==3.26.1
      - mmh3==5.2.0
      - mpmath==1.3.0
      - multidict==6.6.4
      - mypy-extensions==1.1.0
      - networkx==3.5
      - nltk==3.9.1
      - ollama==0.5.3
      - onnxruntime==1.22.1
      - openai==1.102.0
      - pillow==11.3.0
      - pluggy==1.6.0
      - portalocker==3.2.0
      - propcache==0.3.2
      - protobuf==6.32.0
      - py-rust-stemmers==0.1.5
      - pydantic==2.11.7
      - pydantic-core==2.33.2
      - pypdf==6.0.0
      - pytest==8.4.1
      - pytest-asyncio==1.1.0
      - python-dotenv==1.1.1
      - pytz==2025.2
      - pyyaml==6.0.2
      - qdrant-client==1.15.1
      - referencing==0.36.2
      - regex==2025.7.34
      - requests==2.32.5
      - setuptools==80.9.0
      - sniffio==1.3.1
      - soupsieve==2.8
      - sqlalchemy==2.0.43
      - striprtf==0.0.26
      - sympy==1.14.0
      - tabulate==0.9.0
      - tenacity==9.1.2
      - tiktoken==0.11.0
      - tokenizer==3.4.5
      - torch==2.7.1+cu118  # Si usas GPU CUDA, si no, elimina el +cu118
      - torchaudio==2.7.1+cu118
      - torchvision==0.22.1+cu118
      - triton==3.3.1
      - typing-inspect==0.9.0
      - typing-inspection==0.4.1
      - tzdata==2025.2
      - urllib3==2.5.0
      - wrapt==1.17.3
      - yarl==1.20.1
