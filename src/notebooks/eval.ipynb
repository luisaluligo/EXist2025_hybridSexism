{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72902ab8",
   "metadata": {},
   "source": [
    "# 📊 Evaluación de Predicciones de Test con PyEvALL (EXIST2025)\n",
    "\n",
    "Este notebook guía el proceso para evaluar los resultados de predicción del sistema híbrido sobre el set de test de EXIST2025, preparando los archivos en el formato requerido por PyEvALL y mostrando un ejemplo de evaluación automática."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f301b0f5",
   "metadata": {},
   "source": [
    "## 1. Cargar el archivo de predicciones completas\n",
    "\n",
    "Se carga el archivo `complete_dataset_with_predictions.csv` generado previamente, que contiene las predicciones para todas las tareas sobre el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62694b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros cargados: 1038\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_EXIST</th>\n",
       "      <th>lang</th>\n",
       "      <th>tweet</th>\n",
       "      <th>binary_prediction</th>\n",
       "      <th>intention_prediction</th>\n",
       "      <th>category_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300001</td>\n",
       "      <td>es</td>\n",
       "      <td>@Fichinescu La comunidad gamer es un antro de ...</td>\n",
       "      <td>YES</td>\n",
       "      <td>JUDGEMENTAL</td>\n",
       "      <td>['IDEOLOGICAL-INEQUALITY', 'SEXUAL-VIOLENCE', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300002</td>\n",
       "      <td>es</td>\n",
       "      <td>@anacaotica88 @MordorLivin No me acuerdo de lo...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>['NO']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300003</td>\n",
       "      <td>es</td>\n",
       "      <td>@cosmicJunkBot lo digo cada pocos dias y lo re...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>['NO']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300004</td>\n",
       "      <td>es</td>\n",
       "      <td>Also mientras les decia eso la señalaba y deci...</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>['STEREOTYPING-DOMINANCE', 'SEXUAL-VIOLENCE']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300005</td>\n",
       "      <td>es</td>\n",
       "      <td>And all people killed,  attacked, harassed by ...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>['NO']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_EXIST lang                                              tweet  \\\n",
       "0    300001   es  @Fichinescu La comunidad gamer es un antro de ...   \n",
       "1    300002   es  @anacaotica88 @MordorLivin No me acuerdo de lo...   \n",
       "2    300003   es  @cosmicJunkBot lo digo cada pocos dias y lo re...   \n",
       "3    300004   es  Also mientras les decia eso la señalaba y deci...   \n",
       "4    300005   es  And all people killed,  attacked, harassed by ...   \n",
       "\n",
       "  binary_prediction intention_prediction  \\\n",
       "0               YES          JUDGEMENTAL   \n",
       "1                NO                   NO   \n",
       "2                NO                   NO   \n",
       "3               YES                   NO   \n",
       "4                NO                   NO   \n",
       "\n",
       "                                 category_prediction  \n",
       "0  ['IDEOLOGICAL-INEQUALITY', 'SEXUAL-VIOLENCE', ...  \n",
       "1                                             ['NO']  \n",
       "2                                             ['NO']  \n",
       "3      ['STEREOTYPING-DOMINANCE', 'SEXUAL-VIOLENCE']  \n",
       "4                                             ['NO']  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al archivo de predicciones completas\n",
    "csv_path = \"./predicciones_exist2025_dev_final.csv\"\n",
    "\n",
    "# Cargar el DataFrame\n",
    "df = pd.read_csv(csv_path, encoding=\"utf-8\")\n",
    "print(f\"Registros cargados: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b3a918",
   "metadata": {},
   "source": [
    "## 2. Preparar el formato de predicción para PyEvALL (task 1.2 y 1.3)\n",
    "\n",
    "PyEvALL requiere archivos JSON donde cada clave es el `id_EXIST` y el valor es la predicción correspondiente.  \n",
    "- Para **task 1.2**: la predicción es un string (`DIRECT`, `REPORTED`, `JUDGEMENTAL`, `NO`).\n",
    "- Para **task 1.3**: la predicción es una lista de strings (categorías), incluso si solo hay una.\n",
    "\n",
    "Asegúrate de que los valores estén correctamente formateados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e1c0169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo task 1.1: {'500012': 'YES', '500019': 'YES', '500020': 'YES'}\n",
      "Ejemplo task 1.2: {'500012': 'NO', '500019': 'DIRECT', '500020': 'DIRECT'}\n",
      "Ejemplo task 1.3: {'500012': ['STEREOTYPING-DOMINANCE', 'SEXUAL-VIOLENCE'], '500019': ['IDEOLOGICAL-INEQUALITY', 'STEREOTYPING-DOMINANCE'], '500020': ['SEXUAL-VIOLENCE', 'MISOGYNY-NON-SEXUAL-VIOLENCE']}\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Asegurarse de que 'category_prediction' es una lista (puede venir como string)\n",
    "def parse_category(val):\n",
    "    if isinstance(val, list):\n",
    "        return val\n",
    "    if isinstance(val, str):\n",
    "        try:\n",
    "            return ast.literal_eval(val)\n",
    "        except Exception:\n",
    "            return [val]\n",
    "    return [val]\n",
    "\n",
    "df[\"category_prediction\"] = df[\"category_prediction\"].apply(parse_category)\n",
    "\n",
    "# Diccionario para task 1.1 (binaria)\n",
    "pred_task1_1 = {\n",
    "    str(row[\"id_EXIST\"]): row[\"binary_prediction\"]\n",
    "    for _, row in df.iterrows()\n",
    "}\n",
    "\n",
    "# Diccionario para task 1.2 (intención)\n",
    "pred_task1_2 = {\n",
    "    str(row[\"id_EXIST\"]): row[\"intention_prediction\"]\n",
    "    for _, row in df.iterrows()\n",
    "}\n",
    "\n",
    "# Diccionario para task 1.3 (categorías)\n",
    "pred_task1_3 = {\n",
    "    str(row[\"id_EXIST\"]): row[\"category_prediction\"]\n",
    "    for _, row in df.iterrows()\n",
    "}\n",
    "\n",
    "# Ejemplo de los primeros 3 elementos\n",
    "print(\"Ejemplo task 1.1:\", dict(list(pred_task1_1.items())[:3]))\n",
    "print(\"Ejemplo task 1.2:\", dict(list(pred_task1_2.items())[:3]))\n",
    "print(\"Ejemplo task 1.3:\", dict(list(pred_task1_3.items())[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f2a6a4",
   "metadata": {},
   "source": [
    "## 3. Guardar los archivos de predicción en formato JSON para PyEvALL\n",
    "\n",
    "Se guardan los diccionarios de predicción en archivos JSON, listos para ser usados por PyEvALL en la evaluación oficial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "954b325f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos exportados en formato oficial EXIST2025.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Cargar el dataset de predicciones\n",
    "df = pd.read_csv(\"predicciones_exist2025_dev_final.csv\", dtype={\"id_EXIST\": str})\n",
    "\n",
    "# --- 1. Task 1.1 (binaria) ---\n",
    "task1_1_json = [\n",
    "    {\n",
    "        \"test_case\": \"EXIST2025\",\n",
    "        \"id\": row[\"id_EXIST\"],\n",
    "        \"value\": row[\"binary_prediction\"]\n",
    "    }\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "with open(\"EXIST2025_task1_1_pred_hard.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(task1_1_json, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# --- 2. Task 1.2 (intención) ---\n",
    "task1_2_json = [\n",
    "    {\n",
    "        \"test_case\": \"EXIST2025\",\n",
    "        \"id\": row[\"id_EXIST\"],\n",
    "        \"value\": row[\"intention_prediction\"]\n",
    "    }\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "with open(\"EXIST2025_task1_2_pred_soft.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(task1_2_json, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# --- 3. Task 1.3 (categorías, debe ser lista) ---\n",
    "# Si la columna es string, conviértela a lista\n",
    "if isinstance(df[\"category_prediction\"].iloc[0], str):\n",
    "    df[\"category_prediction\"] = df[\"category_prediction\"].apply(eval)\n",
    "\n",
    "task1_3_json = [\n",
    "    {\n",
    "        \"test_case\": \"EXIST2025\",\n",
    "        \"id\": row[\"id_EXIST\"],\n",
    "        \"value\": row[\"category_prediction\"]\n",
    "    }\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "with open(\"EXIST2025_task1_3_pred_soft.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(task1_3_json, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Archivos exportados en formato oficial EXIST2025.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a64477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos guardados: task1_2_soft.json, task1_3_soft.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./data/goldDev/EXIST2025_task1_1_pred_hard.json.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(pred_task1_1, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Guardar predicciones para task 1.2\n",
    "with open(\"./task1_2_hard_CodEXIST2025_task1_1_pred_hard.jsonHerGuard_1.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(pred_task1_2, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Guardar predicciones para task 1.3\n",
    "with open(\"./EXIST2025_task1_1_pred_hard.json.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(pred_task1_3, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Archivos guardados: task1_1_hard_CodeHerGuard_1.json task1_2_hard_CodeHerGuard_1.json, task1_3_hard_CodeHerGuard_1.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88250eea",
   "metadata": {},
   "source": [
    "## 4. Ejemplo de evaluación con PyEvALL para el modelo hibrido\n",
    "\n",
    "A continuación se muestra cómo cargar los archivos de predicción y gold estándar, y ejecutar la evaluación usando PyEvALL.  \n",
    "Asegúrate de tener instalado el paquete `pyevall` y de contar con los archivos gold oficiales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a85b15c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-01 01:05:24,565 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICM', 'ICMNorm', 'FMeasure']\n",
      "2025-09-01 01:05:24,612 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:05:24,749 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Normalized evaluation method\n",
      "2025-09-01 01:05:24,750 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:05:24,865 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:05:24,976 - pyevall.metrics.metrics - INFO -             evaluate() - Executing fmeasure evaluation method\n",
      "{\n",
      "  \"metrics\": {\n",
      "    \"ICM\": {\n",
      "      \"name\": \"Information Contrast model\",\n",
      "      \"acronym\": \"ICM\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"average\": 0.36681500443906834\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.36681500443906834\n",
      "      }\n",
      "    },\n",
      "    \"ICMNorm\": {\n",
      "      \"name\": \"Normalized Information Contrast Model\",\n",
      "      \"acronym\": \"ICM-Norm\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"average\": 0.6834949089944867\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.6834949089944867\n",
      "      }\n",
      "    },\n",
      "    \"FMeasure\": {\n",
      "      \"name\": \"F-Measure\",\n",
      "      \"acronym\": \"F1\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"classes\": {\n",
      "            \"YES\": 0.7353951890034364,\n",
      "            \"NO\": 0.7588717015468609\n",
      "          },\n",
      "          \"average\": 0.7471334452751486\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.7471334452751486\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"files\": {\n",
      "    \"EXIST2025_task1_1_pred_hard.json\": {\n",
      "      \"name\": \"EXIST2025_task1_1_pred_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": false,\n",
      "      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2025_task1_1_pred_hard.json.\",\n",
      "      \"errors\": {}\n",
      "    },\n",
      "    \"EXIST2025_dev_task1_1_gold_hard.json\": {\n",
      "      \"name\": \"EXIST2025_dev_task1_1_gold_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": true,\n",
      "      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2025_dev_task1_1_gold_hard.json.\",\n",
      "      \"errors\": {}\n",
      "    }\n",
      "  }\n",
      "}\n",
      "2025-09-01 01:05:25,088 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICM', 'ICMNorm', 'FMeasure']\n",
      "2025-09-01 01:05:25,130 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:05:25,238 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Normalized evaluation method\n",
      "2025-09-01 01:05:25,238 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:05:25,344 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:05:25,444 - pyevall.metrics.metrics - INFO -             evaluate() - Executing fmeasure evaluation method\n",
      "{\n",
      "  \"metrics\": {\n",
      "    \"ICM\": {\n",
      "      \"name\": \"Information Contrast model\",\n",
      "      \"acronym\": \"ICM\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"average\": -0.13025136630330394\n",
      "        }],\n",
      "        \"average_per_test_case\": -0.13025136630330394\n",
      "      }\n",
      "    },\n",
      "    \"ICMNorm\": {\n",
      "      \"name\": \"Normalized Information Contrast Model\",\n",
      "      \"acronym\": \"ICM-Norm\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"average\": 0.45926921099036205\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.45926921099036205\n",
      "      }\n",
      "    },\n",
      "    \"FMeasure\": {\n",
      "      \"name\": \"F-Measure\",\n",
      "      \"acronym\": \"F1\",\n",
      "      \"description\": \"Coming soon!\\\\nThe evaluation WARNING.\",\n",
      "      \"status\": \"WARNING\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"classes\": {\n",
      "            \"JUDGEMENTAL\": 0.16049382716049382,\n",
      "            \"NO\": 0.7502238137869294,\n",
      "            \"REPORTED\": 0.10101010101010101,\n",
      "            \"DIRECT\": 0.5668662674650699\n",
      "          },\n",
      "          \"average\": 0.3946485023556485\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.3946485023556485\n",
      "      },\n",
      "      \"preconditions\": {\n",
      "        \"METRIC_PRECONDITION_HIERARCHY_NOT_VALID_FOR_METRIC\": {\n",
      "          \"name\": \"METRIC_PRECONDITION_HIERARCHY_NOT_VALID_FOR_METRIC\",\n",
      "          \"description\": \"The hierarchy is provided for the evaluation but this metric does not allow to use it. Hierarchy is ignored.\\\\nThe metric name is: F-Measure.\\\\nTest case(s) name: EXIST2025.\",\n",
      "          \"status\": \"WARNING\",\n",
      "          \"test_cases\": [\"EXIST2025\"]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"files\": {\n",
      "    \"EXIST2025_task1_2_pred_hard.json\": {\n",
      "      \"name\": \"EXIST2025_task1_2_pred_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": false,\n",
      "      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2025_task1_2_pred_hard.json.\",\n",
      "      \"errors\": {}\n",
      "    },\n",
      "    \"EXIST2025_dev_task1_2_gold_hard.json\": {\n",
      "      \"name\": \"EXIST2025_dev_task1_2_gold_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": true,\n",
      "      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2025_dev_task1_2_gold_hard.json.\",\n",
      "      \"errors\": {}\n",
      "    }\n",
      "  }\n",
      "}\n",
      "2025-09-01 01:05:25,546 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICM', 'ICMNorm', 'FMeasure']\n",
      "2025-09-01 01:05:25,610 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:05:25,764 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Normalized evaluation method\n",
      "2025-09-01 01:05:25,765 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:05:25,915 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:05:26,058 - pyevall.metrics.metrics - INFO -             evaluate() - Executing fmeasure evaluation method\n",
      "{\n",
      "  \"metrics\": {\n",
      "    \"ICM\": {\n",
      "      \"name\": \"Information Contrast model\",\n",
      "      \"acronym\": \"ICM\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"average\": -0.41315171322965805\n",
      "        }],\n",
      "        \"average_per_test_case\": -0.41315171322965805\n",
      "      }\n",
      "    },\n",
      "    \"ICMNorm\": {\n",
      "      \"name\": \"Normalized Information Contrast Model\",\n",
      "      \"acronym\": \"ICM-Norm\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"average\": 0.40797605968083545\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.40797605968083545\n",
      "      }\n",
      "    },\n",
      "    \"FMeasure\": {\n",
      "      \"name\": \"F-Measure\",\n",
      "      \"acronym\": \"F1\",\n",
      "      \"description\": \"Coming soon!\\\\nThe evaluation WARNING.\",\n",
      "      \"status\": \"WARNING\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"classes\": {\n",
      "            \"IDEOLOGICAL-INEQUALITY\": 0.4560570071258907,\n",
      "            \"STEREOTYPING-DOMINANCE\": 0.48582995951416996,\n",
      "            \"MISOGYNY-NON-SEXUAL-VIOLENCE\": 0.40522875816993464,\n",
      "            \"NO\": 0.7599999999999999,\n",
      "            \"SEXUAL-VIOLENCE\": 0.34983498349834985,\n",
      "            \"OBJECTIFICATION\": 0.4831804281345566\n",
      "          },\n",
      "          \"average\": 0.49002185607381693\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.49002185607381693\n",
      "      },\n",
      "      \"preconditions\": {\n",
      "        \"METRIC_PRECONDITION_HIERARCHY_NOT_VALID_FOR_METRIC\": {\n",
      "          \"name\": \"METRIC_PRECONDITION_HIERARCHY_NOT_VALID_FOR_METRIC\",\n",
      "          \"description\": \"The hierarchy is provided for the evaluation but this metric does not allow to use it. Hierarchy is ignored.\\\\nThe metric name is: F-Measure.\\\\nTest case(s) name: EXIST2025.\",\n",
      "          \"status\": \"WARNING\",\n",
      "          \"test_cases\": [\"EXIST2025\"]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"files\": {\n",
      "    \"EXIST2025_task1_3_pred_hard.json\": {\n",
      "      \"name\": \"EXIST2025_task1_3_pred_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": false,\n",
      "      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2025_task1_3_pred_hard.json.\",\n",
      "      \"errors\": {}\n",
      "    },\n",
      "    \"EXIST2025_dev_task1_3_gold_hard.json\": {\n",
      "      \"name\": \"EXIST2025_dev_task1_3_gold_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": true,\n",
      "      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2025_dev_task1_3_gold_hard.json.\",\n",
      "      \"errors\": {}\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pyevall.evaluation import PyEvALLEvaluation\n",
    "from pyevall.utils.utils import PyEvALLUtils\n",
    "\n",
    "# Archivos de predicción y gold para hard\n",
    "pred_1_1 = \"/home/luisa-fernanda/Descargas/pers/sre/src/data/goldDEV/EXIST2025_task1_1_pred_hard.json\"\n",
    "gold_1_1 = \"/home/luisa-fernanda/Descargas/pers/sre/evaluation/golds/EXIST2025_dev_task1_1_gold_hard.json\"\n",
    "\n",
    "pred_1_2 = \"/home/luisa-fernanda/Descargas/pers/sre/src/data/goldDEV/EXIST2025_task1_2_pred_hard.json\"\n",
    "gold_1_2 = \"/home/luisa-fernanda/Descargas/pers/sre/evaluation/golds/EXIST2025_dev_task1_2_gold_hard.json\"\n",
    "\n",
    "pred_1_3 = \"/home/luisa-fernanda/Descargas/pers/sre/src/data/goldDEV/EXIST2025_task1_3_pred_hard.json\"\n",
    "gold_1_3 = \"/home/luisa-fernanda/Descargas/pers/sre/evaluation/golds/EXIST2025_dev_task1_3_gold_hard.json\"\n",
    "\n",
    "metrics = [\"ICM\", \"ICMNorm\", \"FMeasure\"]\n",
    "\n",
    "evaluator = PyEvALLEvaluation()\n",
    "\n",
    "# Task 1.1 (no jerarquía)\n",
    "params_1_1 = {\n",
    "    PyEvALLUtils.PARAM_REPORT: PyEvALLUtils.PARAM_OPTION_REPORT_EMBEDDED\n",
    "}\n",
    "report_1_1 = evaluator.evaluate(pred_1_1, gold_1_1, metrics,**params_1_1)\n",
    "report_1_1.print_report()\n",
    "\n",
    "# Task 1.2 (con jerarquía)\n",
    "TASK1_2_HIERARCHY = {\"YES\": [\"DIRECT\", \"REPORTED\", \"JUDGEMENTAL\"], \"NO\": []}\n",
    "params_1_2 = {\n",
    "    PyEvALLUtils.PARAM_HIERARCHY: TASK1_2_HIERARCHY,\n",
    "    PyEvALLUtils.PARAM_REPORT: PyEvALLUtils.PARAM_OPTION_REPORT_EMBEDDED\n",
    "}\n",
    "report_1_2 = evaluator.evaluate(pred_1_2, gold_1_2, metrics, **params_1_2)\n",
    "report_1_2.print_report()\n",
    "\n",
    "# Task 1.3 (con jerarquía)\n",
    "TASK1_3_HIERARCHY = {\n",
    "    \"YES\": [\n",
    "        \"IDEOLOGICAL-INEQUALITY\",\n",
    "        \"STEREOTYPING-DOMINANCE\",\n",
    "        \"OBJECTIFICATION\",\n",
    "        \"SEXUAL-VIOLENCE\",\n",
    "        \"MISOGYNY-NON-SEXUAL-VIOLENCE\"\n",
    "    ],\n",
    "    \"NO\": []\n",
    "}\n",
    "params_1_3 = {\n",
    "    PyEvALLUtils.PARAM_HIERARCHY: TASK1_3_HIERARCHY,\n",
    "    PyEvALLUtils.PARAM_REPORT: PyEvALLUtils.PARAM_OPTION_REPORT_EMBEDDED\n",
    "}\n",
    "report_1_3 = evaluator.evaluate(pred_1_3, gold_1_3, metrics, **params_1_3)\n",
    "report_1_3.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f32298c",
   "metadata": {},
   "source": [
    "\n",
    "## Resultados evaluacion modelo hibrido\n",
    "\n",
    "\n",
    "### Task 1.1 (Binaria)\n",
    "\n",
    "| Métrica   |   Valor   |\n",
    "|:---------:|:---------:|\n",
    "| ICM       | 0.3668    |\n",
    "| ICM-Norm  | 0.6835    |\n",
    "| F1        | 0.7471    |\n",
    "| F1-YES    | 0.7354    |\n",
    "| F1-NO     | 0.7589    |\n",
    "\n",
    "---\n",
    "\n",
    "### Task 1.2 (Intención)\n",
    "\n",
    "| Métrica   |   Valor   |\n",
    "|:---------:|:---------:|\n",
    "| ICM       | -0.1303   |\n",
    "| ICM-Norm  | 0.4593    |\n",
    "| F1        | 0.3946    |\n",
    "| F1-DIRECT | 0.5669    |\n",
    "| F1-REPORTED | 0.1010  |\n",
    "| F1-JUDGEMENTAL | 0.1605 |\n",
    "| F1-NO     | 0.7502    |\n",
    "\n",
    "---\n",
    "\n",
    "### Task 1.3 (Categorías)\n",
    "\n",
    "| Métrica   |   Valor   |\n",
    "|:----------------------------:|:---------:|\n",
    "| ICM                           | -0.4132   |\n",
    "| ICM-Norm                      | 0.4080    |\n",
    "| F1                            | 0.4900    |\n",
    "| F1-IDEOLOGICAL-INEQUALITY     | 0.4561    |\n",
    "| F1-STEREOTYPING-DOMINANCE     | 0.4858    |\n",
    "| F1-OBJECTIFICATION            | 0.4832    |\n",
    "| F1-SEXUAL-VIOLENCE            | 0.3498    |\n",
    "| F1-MISOGYNY-NON-SEXUAL-VIOLENCE | 0.4052  |\n",
    "| F1-NO                         | 0.7600    |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e7ba1b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b245f84",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "085a8817",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "360069ce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7757589",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88710fc1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "427c9598",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a71acd17",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4df2d1c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "066b87ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80cec996",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e53ca225",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8a76fee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8574f936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-01 01:04:25,411 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICM', 'ICMNorm', 'FMeasure']\n",
      "2025-09-01 01:04:25,457 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:04:25,568 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Normalized evaluation method\n",
      "2025-09-01 01:04:25,569 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:04:25,686 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:04:25,808 - pyevall.metrics.metrics - INFO -             evaluate() - Executing fmeasure evaluation method\n",
      "{\n",
      "  \"metrics\": {\n",
      "    \"ICM\": {\n",
      "      \"name\": \"Information Contrast model\",\n",
      "      \"acronym\": \"ICM\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"average\": 0.5785920013897591\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.5785920013897591\n",
      "      }\n",
      "    },\n",
      "    \"ICMNorm\": {\n",
      "      \"name\": \"Normalized Information Contrast Model\",\n",
      "      \"acronym\": \"ICM-Norm\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"average\": 0.7894338709025941\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.7894338709025941\n",
      "      }\n",
      "    },\n",
      "    \"FMeasure\": {\n",
      "      \"name\": \"F-Measure\",\n",
      "      \"acronym\": \"F1\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"classes\": {\n",
      "            \"YES\": 0.8074534161490683,\n",
      "            \"NO\": 0.8210735586481113\n",
      "          },\n",
      "          \"average\": 0.8142634873985898\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.8142634873985898\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"files\": {\n",
      "    \"predictions_task1_1.json\": {\n",
      "      \"name\": \"predictions_task1_1.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": false,\n",
      "      \"description\": \"Use parameter: report=\\\"embedded\\\"!\",\n",
      "      \"errors\": {}\n",
      "    },\n",
      "    \"EXIST2025_dev_task1_1_gold_hard.json\": {\n",
      "      \"name\": \"EXIST2025_dev_task1_1_gold_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": true,\n",
      "      \"description\": \"Use parameter: report=\\\"embedded\\\"!\",\n",
      "      \"errors\": {}\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pred_1_1tf = \"/home/luisa-fernanda/Descargas/pers/sre/src/notebooks/predictions_task1_1.json\"\n",
    "gold_1_1 = \"/home/luisa-fernanda/Descargas/pers/sre/evaluation/golds/EXIST2025_dev_task1_1_gold_hard.json\"\n",
    "\n",
    "\n",
    "params_1_1 = {\n",
    "    PyEvALLUtils.PARAM_REPORT: PyEvALLUtils.PARAM_OPTION_REPORT_DATAFRAME\n",
    "}\n",
    "report_1_1_tra = evaluator.evaluate(pred_1_1tf, gold_1_1, metrics)\n",
    "\n",
    "report_1_1_tra.print_report()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a8a334",
   "metadata": {},
   "source": [
    "## Comparativa de Modelos segun pyevall para la task 1.1\n",
    "\n",
    "| Modelo       |     ICM    | ICM-Norm |    F1   |  F1-YES  |  F1-NO  |\n",
    "|:------------:|:----------:|:--------:|:-------:|:--------:|:-------:|\n",
    "| Híbrido      | 0.3668     | 0.6835   | 0.7471  | 0.7354   | 0.7589  |\n",
    "| Transformer  | 0.5786     | 0.7894   | 0.8143  | 0.8075   | 0.8211  |\n",
    "\n",
    "En la tabla anterior se presenta una comparativa entre los modelos evaluados. El modelo **Transformer** supera al modelo **Híbrido** en todas las métricas, destacándose especialmente en el índice ICM-Norm y la métrica F1. Esto sugiere que el modelo Transformer tiene un mejor desempeño general en la tarea evaluada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "163dc6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-01 01:03:40,208 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICM', 'ICMNorm', 'FMeasure']\n",
      "2025-09-01 01:03:40,256 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:03:40,360 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Normalized evaluation method\n",
      "2025-09-01 01:03:40,360 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:03:40,464 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:03:40,562 - pyevall.metrics.metrics - INFO -             evaluate() - Executing fmeasure evaluation method\n",
      "{\n",
      "  \"metrics\": {\n",
      "    \"ICM\": {\n",
      "      \"name\": \"Information Contrast model\",\n",
      "      \"acronym\": \"ICM\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"average\": -2.854364098946497\n",
      "        }],\n",
      "        \"average_per_test_case\": -2.854364098946497\n",
      "      }\n",
      "    },\n",
      "    \"ICMNorm\": {\n",
      "      \"name\": \"Normalized Information Contrast Model\",\n",
      "      \"acronym\": \"ICM-Norm\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"average\": 0\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.0\n",
      "      }\n",
      "    },\n",
      "    \"FMeasure\": {\n",
      "      \"name\": \"F-Measure\",\n",
      "      \"acronym\": \"F1\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"classes\": {\n",
      "            \"JUDGEMENTAL\": 0.031746031746031744,\n",
      "            \"NO\": 0.11374407582938387,\n",
      "            \"REPORTED\": 0.14814814814814814,\n",
      "            \"DIRECT\": 0.6090712742980562\n",
      "          },\n",
      "          \"average\": 0.22567738250540498\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.22567738250540498\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"files\": {\n",
      "    \"predictions_task1_2_devTransformer.json\": {\n",
      "      \"name\": \"predictions_task1_2_devTransformer.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": false,\n",
      "      \"description\": \"Use parameter: report=\\\"embedded\\\"!\",\n",
      "      \"errors\": {}\n",
      "    },\n",
      "    \"EXIST2025_dev_task1_2_gold_hard.json\": {\n",
      "      \"name\": \"EXIST2025_dev_task1_2_gold_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": true,\n",
      "      \"description\": \"Use parameter: report=\\\"embedded\\\"!\",\n",
      "      \"errors\": {}\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pred_1_2tf = \"/home/luisa-fernanda/Descargas/pers/sre/src/notebooks/predictions_task1_2_devTransformer.json\"\n",
    "\n",
    "params_1_2 = {\n",
    "    PyEvALLUtils.PARAM_HIERARCHY: TASK1_2_HIERARCHY,\n",
    "    PyEvALLUtils.PARAM_REPORT: PyEvALLUtils.PARAM_OPTION_REPORT_DATAFRAME\n",
    "}\n",
    "report_1_2_tra = evaluator.evaluate(pred_1_2tf, gold_1_2, metrics)\n",
    "\n",
    "report_1_2_tra.print_report()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b09e1e2",
   "metadata": {},
   "source": [
    "\n",
    "## Comparativa de Modelos segun pyevall para la task 1.2\n",
    "\n",
    "| Modelo       |    ICM    | ICM-Norm |   F1   | F1-DIRECT | F1-REPORTED | F1-JUDGEMENTAL | F1-NO   |\n",
    "|:------------:|:---------:|:--------:|:------:|:---------:|:-----------:|:--------------:|:-------:|\n",
    "| Híbrido      | -0.1303   | 0.4593   | 0.3946 | 0.5669    | 0.1010      | 0.1605         | 0.7502  |\n",
    "| Transformer  | -2.8544   | 0.0000   | 0.2257 | 0.6091    | 0.1481      | 0.0317         | 0.1137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a645e16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi_entorno_analisis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
