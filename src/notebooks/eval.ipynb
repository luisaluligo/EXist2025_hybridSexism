{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72902ab8",
   "metadata": {},
   "source": [
    "#  Evaluaci贸n de Predicciones de Test con PyEvALL (EXIST2025)\n",
    "\n",
    "Este notebook gu铆a el proceso para evaluar los resultados de predicci贸n del sistema h铆brido sobre el set de test de EXIST2025, preparando los archivos en el formato requerido por PyEvALL y mostrando un ejemplo de evaluaci贸n autom谩tica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f301b0f5",
   "metadata": {},
   "source": [
    "## 1. Cargar el archivo de predicciones completas\n",
    "\n",
    "Se carga el archivo `complete_dataset_with_predictions.csv` generado previamente, que contiene las predicciones para todas las tareas sobre el conjunto de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62694b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros cargados: 1038\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_EXIST</th>\n",
       "      <th>lang</th>\n",
       "      <th>tweet</th>\n",
       "      <th>binary_prediction</th>\n",
       "      <th>intention_prediction</th>\n",
       "      <th>category_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300001</td>\n",
       "      <td>es</td>\n",
       "      <td>@Fichinescu La comunidad gamer es un antro de ...</td>\n",
       "      <td>YES</td>\n",
       "      <td>JUDGEMENTAL</td>\n",
       "      <td>['IDEOLOGICAL-INEQUALITY', 'SEXUAL-VIOLENCE', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300002</td>\n",
       "      <td>es</td>\n",
       "      <td>@anacaotica88 @MordorLivin No me acuerdo de lo...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>['NO']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300003</td>\n",
       "      <td>es</td>\n",
       "      <td>@cosmicJunkBot lo digo cada pocos dias y lo re...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>['NO']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300004</td>\n",
       "      <td>es</td>\n",
       "      <td>Also mientras les decia eso la se帽alaba y deci...</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>['STEREOTYPING-DOMINANCE', 'SEXUAL-VIOLENCE']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300005</td>\n",
       "      <td>es</td>\n",
       "      <td>And all people killed,  attacked, harassed by ...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>['NO']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_EXIST lang                                              tweet  \\\n",
       "0    300001   es  @Fichinescu La comunidad gamer es un antro de ...   \n",
       "1    300002   es  @anacaotica88 @MordorLivin No me acuerdo de lo...   \n",
       "2    300003   es  @cosmicJunkBot lo digo cada pocos dias y lo re...   \n",
       "3    300004   es  Also mientras les decia eso la se帽alaba y deci...   \n",
       "4    300005   es  And all people killed,  attacked, harassed by ...   \n",
       "\n",
       "  binary_prediction intention_prediction  \\\n",
       "0               YES          JUDGEMENTAL   \n",
       "1                NO                   NO   \n",
       "2                NO                   NO   \n",
       "3               YES                   NO   \n",
       "4                NO                   NO   \n",
       "\n",
       "                                 category_prediction  \n",
       "0  ['IDEOLOGICAL-INEQUALITY', 'SEXUAL-VIOLENCE', ...  \n",
       "1                                             ['NO']  \n",
       "2                                             ['NO']  \n",
       "3      ['STEREOTYPING-DOMINANCE', 'SEXUAL-VIOLENCE']  \n",
       "4                                             ['NO']  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al archivo de predicciones completas\n",
    "csv_path = \"./predicciones_exist2025_dev_final.csv\"\n",
    "\n",
    "# Cargar el DataFrame\n",
    "df = pd.read_csv(csv_path, encoding=\"utf-8\")\n",
    "print(f\"Registros cargados: {len(df)}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b3a918",
   "metadata": {},
   "source": [
    "## 2. Preparar el formato de predicci贸n para PyEvALL (task 1.2 y 1.3)\n",
    "\n",
    "PyEvALL requiere archivos JSON donde cada clave es el `id_EXIST` y el valor es la predicci贸n correspondiente.  \n",
    "- Para **task 1.2**: la predicci贸n es un string (`DIRECT`, `REPORTED`, `JUDGEMENTAL`, `NO`).\n",
    "- Para **task 1.3**: la predicci贸n es una lista de strings (categor铆as), incluso si solo hay una.\n",
    "\n",
    "Aseg煤rate de que los valores est茅n correctamente formateados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e1c0169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo task 1.1: {'500012': 'YES', '500019': 'YES', '500020': 'YES'}\n",
      "Ejemplo task 1.2: {'500012': 'NO', '500019': 'DIRECT', '500020': 'DIRECT'}\n",
      "Ejemplo task 1.3: {'500012': ['STEREOTYPING-DOMINANCE', 'SEXUAL-VIOLENCE'], '500019': ['IDEOLOGICAL-INEQUALITY', 'STEREOTYPING-DOMINANCE'], '500020': ['SEXUAL-VIOLENCE', 'MISOGYNY-NON-SEXUAL-VIOLENCE']}\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Asegurarse de que 'category_prediction' es una lista (puede venir como string)\n",
    "def parse_category(val):\n",
    "    if isinstance(val, list):\n",
    "        return val\n",
    "    if isinstance(val, str):\n",
    "        try:\n",
    "            return ast.literal_eval(val)\n",
    "        except Exception:\n",
    "            return [val]\n",
    "    return [val]\n",
    "\n",
    "df[\"category_prediction\"] = df[\"category_prediction\"].apply(parse_category)\n",
    "\n",
    "# Diccionario para task 1.1 (binaria)\n",
    "pred_task1_1 = {\n",
    "    str(row[\"id_EXIST\"]): row[\"binary_prediction\"]\n",
    "    for _, row in df.iterrows()\n",
    "}\n",
    "\n",
    "# Diccionario para task 1.2 (intenci贸n)\n",
    "pred_task1_2 = {\n",
    "    str(row[\"id_EXIST\"]): row[\"intention_prediction\"]\n",
    "    for _, row in df.iterrows()\n",
    "}\n",
    "\n",
    "# Diccionario para task 1.3 (categor铆as)\n",
    "pred_task1_3 = {\n",
    "    str(row[\"id_EXIST\"]): row[\"category_prediction\"]\n",
    "    for _, row in df.iterrows()\n",
    "}\n",
    "\n",
    "# Ejemplo de los primeros 3 elementos\n",
    "print(\"Ejemplo task 1.1:\", dict(list(pred_task1_1.items())[:3]))\n",
    "print(\"Ejemplo task 1.2:\", dict(list(pred_task1_2.items())[:3]))\n",
    "print(\"Ejemplo task 1.3:\", dict(list(pred_task1_3.items())[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f2a6a4",
   "metadata": {},
   "source": [
    "## 3. Guardar los archivos de predicci贸n en formato JSON para PyEvALL\n",
    "\n",
    "Se guardan los diccionarios de predicci贸n en archivos JSON, listos para ser usados por PyEvALL en la evaluaci贸n oficial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "954b325f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos exportados en formato oficial EXIST2025.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Cargar el dataset de predicciones\n",
    "df = pd.read_csv(\"predicciones_exist2025_dev_final.csv\", dtype={\"id_EXIST\": str})\n",
    "\n",
    "# --- 1. Task 1.1 (binaria) ---\n",
    "task1_1_json = [\n",
    "    {\n",
    "        \"test_case\": \"EXIST2025\",\n",
    "        \"id\": row[\"id_EXIST\"],\n",
    "        \"value\": row[\"binary_prediction\"]\n",
    "    }\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "with open(\"EXIST2025_task1_1_pred_hard.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(task1_1_json, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# --- 2. Task 1.2 (intenci贸n) ---\n",
    "task1_2_json = [\n",
    "    {\n",
    "        \"test_case\": \"EXIST2025\",\n",
    "        \"id\": row[\"id_EXIST\"],\n",
    "        \"value\": row[\"intention_prediction\"]\n",
    "    }\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "with open(\"EXIST2025_task1_2_pred_soft.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(task1_2_json, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# --- 3. Task 1.3 (categor铆as, debe ser lista) ---\n",
    "# Si la columna es string, convi茅rtela a lista\n",
    "if isinstance(df[\"category_prediction\"].iloc[0], str):\n",
    "    df[\"category_prediction\"] = df[\"category_prediction\"].apply(eval)\n",
    "\n",
    "task1_3_json = [\n",
    "    {\n",
    "        \"test_case\": \"EXIST2025\",\n",
    "        \"id\": row[\"id_EXIST\"],\n",
    "        \"value\": row[\"category_prediction\"]\n",
    "    }\n",
    "    for _, row in df.iterrows()\n",
    "]\n",
    "with open(\"EXIST2025_task1_3_pred_soft.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(task1_3_json, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Archivos exportados en formato oficial EXIST2025.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a64477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos guardados: task1_2_soft.json, task1_3_soft.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./data/goldDev/EXIST2025_task1_1_pred_hard.json.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(pred_task1_1, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Guardar predicciones para task 1.2\n",
    "with open(\"./task1_2_hard_CodEXIST2025_task1_1_pred_hard.jsonHerGuard_1.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(pred_task1_2, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Guardar predicciones para task 1.3\n",
    "with open(\"./EXIST2025_task1_1_pred_hard.json.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(pred_task1_3, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Archivos guardados: task1_1_hard_CodeHerGuard_1.json task1_2_hard_CodeHerGuard_1.json, task1_3_hard_CodeHerGuard_1.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88250eea",
   "metadata": {},
   "source": [
    "## 4. Ejemplo de evaluaci贸n con PyEvALL para el modelo hibrido\n",
    "\n",
    "A continuaci贸n se muestra c贸mo cargar los archivos de predicci贸n y gold est谩ndar, y ejecutar la evaluaci贸n usando PyEvALL.  \n",
    "Aseg煤rate de tener instalado el paquete `pyevall` y de contar con los archivos gold oficiales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a85b15c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-01 01:05:24,565 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICM', 'ICMNorm', 'FMeasure']\n",
      "2025-09-01 01:05:24,612 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:05:24,749 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Normalized evaluation method\n",
      "2025-09-01 01:05:24,750 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:05:24,865 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:05:24,976 - pyevall.metrics.metrics - INFO -             evaluate() - Executing fmeasure evaluation method\n",
      "{\n",
      "  \"metrics\": {\n",
      "    \"ICM\": {\n",
      "      \"name\": \"Information Contrast model\",\n",
      "      \"acronym\": \"ICM\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"average\": 0.36681500443906834\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.36681500443906834\n",
      "      }\n",
      "    },\n",
      "    \"ICMNorm\": {\n",
      "      \"name\": \"Normalized Information Contrast Model\",\n",
      "      \"acronym\": \"ICM-Norm\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"average\": 0.6834949089944867\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.6834949089944867\n",
      "      }\n",
      "    },\n",
      "    \"FMeasure\": {\n",
      "      \"name\": \"F-Measure\",\n",
      "      \"acronym\": \"F1\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"classes\": {\n",
      "            \"YES\": 0.7353951890034364,\n",
      "            \"NO\": 0.7588717015468609\n",
      "          },\n",
      "          \"average\": 0.7471334452751486\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.7471334452751486\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"files\": {\n",
      "    \"EXIST2025_task1_1_pred_hard.json\": {\n",
      "      \"name\": \"EXIST2025_task1_1_pred_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": false,\n",
      "      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2025_task1_1_pred_hard.json.\",\n",
      "      \"errors\": {}\n",
      "    },\n",
      "    \"EXIST2025_dev_task1_1_gold_hard.json\": {\n",
      "      \"name\": \"EXIST2025_dev_task1_1_gold_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": true,\n",
      "      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2025_dev_task1_1_gold_hard.json.\",\n",
      "      \"errors\": {}\n",
      "    }\n",
      "  }\n",
      "}\n",
      "2025-09-01 01:05:25,088 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICM', 'ICMNorm', 'FMeasure']\n",
      "2025-09-01 01:05:25,130 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:05:25,238 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Normalized evaluation method\n",
      "2025-09-01 01:05:25,238 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:05:25,344 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:05:25,444 - pyevall.metrics.metrics - INFO -             evaluate() - Executing fmeasure evaluation method\n",
      "{\n",
      "  \"metrics\": {\n",
      "    \"ICM\": {\n",
      "      \"name\": \"Information Contrast model\",\n",
      "      \"acronym\": \"ICM\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"average\": -0.13025136630330394\n",
      "        }],\n",
      "        \"average_per_test_case\": -0.13025136630330394\n",
      "      }\n",
      "    },\n",
      "    \"ICMNorm\": {\n",
      "      \"name\": \"Normalized Information Contrast Model\",\n",
      "      \"acronym\": \"ICM-Norm\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"average\": 0.45926921099036205\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.45926921099036205\n",
      "      }\n",
      "    },\n",
      "    \"FMeasure\": {\n",
      "      \"name\": \"F-Measure\",\n",
      "      \"acronym\": \"F1\",\n",
      "      \"description\": \"Coming soon!\\\\nThe evaluation WARNING.\",\n",
      "      \"status\": \"WARNING\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"classes\": {\n",
      "            \"JUDGEMENTAL\": 0.16049382716049382,\n",
      "            \"NO\": 0.7502238137869294,\n",
      "            \"REPORTED\": 0.10101010101010101,\n",
      "            \"DIRECT\": 0.5668662674650699\n",
      "          },\n",
      "          \"average\": 0.3946485023556485\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.3946485023556485\n",
      "      },\n",
      "      \"preconditions\": {\n",
      "        \"METRIC_PRECONDITION_HIERARCHY_NOT_VALID_FOR_METRIC\": {\n",
      "          \"name\": \"METRIC_PRECONDITION_HIERARCHY_NOT_VALID_FOR_METRIC\",\n",
      "          \"description\": \"The hierarchy is provided for the evaluation but this metric does not allow to use it. Hierarchy is ignored.\\\\nThe metric name is: F-Measure.\\\\nTest case(s) name: EXIST2025.\",\n",
      "          \"status\": \"WARNING\",\n",
      "          \"test_cases\": [\"EXIST2025\"]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"files\": {\n",
      "    \"EXIST2025_task1_2_pred_hard.json\": {\n",
      "      \"name\": \"EXIST2025_task1_2_pred_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": false,\n",
      "      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2025_task1_2_pred_hard.json.\",\n",
      "      \"errors\": {}\n",
      "    },\n",
      "    \"EXIST2025_dev_task1_2_gold_hard.json\": {\n",
      "      \"name\": \"EXIST2025_dev_task1_2_gold_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": true,\n",
      "      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2025_dev_task1_2_gold_hard.json.\",\n",
      "      \"errors\": {}\n",
      "    }\n",
      "  }\n",
      "}\n",
      "2025-09-01 01:05:25,546 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICM', 'ICMNorm', 'FMeasure']\n",
      "2025-09-01 01:05:25,610 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:05:25,764 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Normalized evaluation method\n",
      "2025-09-01 01:05:25,765 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:05:25,915 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:05:26,058 - pyevall.metrics.metrics - INFO -             evaluate() - Executing fmeasure evaluation method\n",
      "{\n",
      "  \"metrics\": {\n",
      "    \"ICM\": {\n",
      "      \"name\": \"Information Contrast model\",\n",
      "      \"acronym\": \"ICM\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"average\": -0.41315171322965805\n",
      "        }],\n",
      "        \"average_per_test_case\": -0.41315171322965805\n",
      "      }\n",
      "    },\n",
      "    \"ICMNorm\": {\n",
      "      \"name\": \"Normalized Information Contrast Model\",\n",
      "      \"acronym\": \"ICM-Norm\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"average\": 0.40797605968083545\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.40797605968083545\n",
      "      }\n",
      "    },\n",
      "    \"FMeasure\": {\n",
      "      \"name\": \"F-Measure\",\n",
      "      \"acronym\": \"F1\",\n",
      "      \"description\": \"Coming soon!\\\\nThe evaluation WARNING.\",\n",
      "      \"status\": \"WARNING\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"classes\": {\n",
      "            \"IDEOLOGICAL-INEQUALITY\": 0.4560570071258907,\n",
      "            \"STEREOTYPING-DOMINANCE\": 0.48582995951416996,\n",
      "            \"MISOGYNY-NON-SEXUAL-VIOLENCE\": 0.40522875816993464,\n",
      "            \"NO\": 0.7599999999999999,\n",
      "            \"SEXUAL-VIOLENCE\": 0.34983498349834985,\n",
      "            \"OBJECTIFICATION\": 0.4831804281345566\n",
      "          },\n",
      "          \"average\": 0.49002185607381693\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.49002185607381693\n",
      "      },\n",
      "      \"preconditions\": {\n",
      "        \"METRIC_PRECONDITION_HIERARCHY_NOT_VALID_FOR_METRIC\": {\n",
      "          \"name\": \"METRIC_PRECONDITION_HIERARCHY_NOT_VALID_FOR_METRIC\",\n",
      "          \"description\": \"The hierarchy is provided for the evaluation but this metric does not allow to use it. Hierarchy is ignored.\\\\nThe metric name is: F-Measure.\\\\nTest case(s) name: EXIST2025.\",\n",
      "          \"status\": \"WARNING\",\n",
      "          \"test_cases\": [\"EXIST2025\"]\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"files\": {\n",
      "    \"EXIST2025_task1_3_pred_hard.json\": {\n",
      "      \"name\": \"EXIST2025_task1_3_pred_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": false,\n",
      "      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2025_task1_3_pred_hard.json.\",\n",
      "      \"errors\": {}\n",
      "    },\n",
      "    \"EXIST2025_dev_task1_3_gold_hard.json\": {\n",
      "      \"name\": \"EXIST2025_dev_task1_3_gold_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": true,\n",
      "      \"description\": \"The file is correctly parser without errors or warnings.\\\\nFile name: EXIST2025_dev_task1_3_gold_hard.json.\",\n",
      "      \"errors\": {}\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pyevall.evaluation import PyEvALLEvaluation\n",
    "from pyevall.utils.utils import PyEvALLUtils\n",
    "\n",
    "# Archivos de predicci贸n y gold para hard\n",
    "pred_1_1 = \"/home/luisa-fernanda/Descargas/pers/sre/src/data/goldDEV/EXIST2025_task1_1_pred_hard.json\"\n",
    "gold_1_1 = \"/home/luisa-fernanda/Descargas/pers/sre/evaluation/golds/EXIST2025_dev_task1_1_gold_hard.json\"\n",
    "\n",
    "pred_1_2 = \"/home/luisa-fernanda/Descargas/pers/sre/src/data/goldDEV/EXIST2025_task1_2_pred_hard.json\"\n",
    "gold_1_2 = \"/home/luisa-fernanda/Descargas/pers/sre/evaluation/golds/EXIST2025_dev_task1_2_gold_hard.json\"\n",
    "\n",
    "pred_1_3 = \"/home/luisa-fernanda/Descargas/pers/sre/src/data/goldDEV/EXIST2025_task1_3_pred_hard.json\"\n",
    "gold_1_3 = \"/home/luisa-fernanda/Descargas/pers/sre/evaluation/golds/EXIST2025_dev_task1_3_gold_hard.json\"\n",
    "\n",
    "metrics = [\"ICM\", \"ICMNorm\", \"FMeasure\"]\n",
    "\n",
    "evaluator = PyEvALLEvaluation()\n",
    "\n",
    "# Task 1.1 (no jerarqu铆a)\n",
    "params_1_1 = {\n",
    "    PyEvALLUtils.PARAM_REPORT: PyEvALLUtils.PARAM_OPTION_REPORT_EMBEDDED\n",
    "}\n",
    "report_1_1 = evaluator.evaluate(pred_1_1, gold_1_1, metrics,**params_1_1)\n",
    "report_1_1.print_report()\n",
    "\n",
    "# Task 1.2 (con jerarqu铆a)\n",
    "TASK1_2_HIERARCHY = {\"YES\": [\"DIRECT\", \"REPORTED\", \"JUDGEMENTAL\"], \"NO\": []}\n",
    "params_1_2 = {\n",
    "    PyEvALLUtils.PARAM_HIERARCHY: TASK1_2_HIERARCHY,\n",
    "    PyEvALLUtils.PARAM_REPORT: PyEvALLUtils.PARAM_OPTION_REPORT_EMBEDDED\n",
    "}\n",
    "report_1_2 = evaluator.evaluate(pred_1_2, gold_1_2, metrics, **params_1_2)\n",
    "report_1_2.print_report()\n",
    "\n",
    "# Task 1.3 (con jerarqu铆a)\n",
    "TASK1_3_HIERARCHY = {\n",
    "    \"YES\": [\n",
    "        \"IDEOLOGICAL-INEQUALITY\",\n",
    "        \"STEREOTYPING-DOMINANCE\",\n",
    "        \"OBJECTIFICATION\",\n",
    "        \"SEXUAL-VIOLENCE\",\n",
    "        \"MISOGYNY-NON-SEXUAL-VIOLENCE\"\n",
    "    ],\n",
    "    \"NO\": []\n",
    "}\n",
    "params_1_3 = {\n",
    "    PyEvALLUtils.PARAM_HIERARCHY: TASK1_3_HIERARCHY,\n",
    "    PyEvALLUtils.PARAM_REPORT: PyEvALLUtils.PARAM_OPTION_REPORT_EMBEDDED\n",
    "}\n",
    "report_1_3 = evaluator.evaluate(pred_1_3, gold_1_3, metrics, **params_1_3)\n",
    "report_1_3.print_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f32298c",
   "metadata": {},
   "source": [
    "\n",
    "## Resultados evaluacion modelo hibrido\n",
    "\n",
    "\n",
    "### Task 1.1 (Binaria)\n",
    "\n",
    "| M茅trica   |   Valor   |\n",
    "|:---------:|:---------:|\n",
    "| ICM       | 0.3668    |\n",
    "| ICM-Norm  | 0.6835    |\n",
    "| F1        | 0.7471    |\n",
    "| F1-YES    | 0.7354    |\n",
    "| F1-NO     | 0.7589    |\n",
    "\n",
    "---\n",
    "\n",
    "### Task 1.2 (Intenci贸n)\n",
    "\n",
    "| M茅trica   |   Valor   |\n",
    "|:---------:|:---------:|\n",
    "| ICM       | -0.1303   |\n",
    "| ICM-Norm  | 0.4593    |\n",
    "| F1        | 0.3946    |\n",
    "| F1-DIRECT | 0.5669    |\n",
    "| F1-REPORTED | 0.1010  |\n",
    "| F1-JUDGEMENTAL | 0.1605 |\n",
    "| F1-NO     | 0.7502    |\n",
    "\n",
    "---\n",
    "\n",
    "### Task 1.3 (Categor铆as)\n",
    "\n",
    "| M茅trica   |   Valor   |\n",
    "|:----------------------------:|:---------:|\n",
    "| ICM                           | -0.4132   |\n",
    "| ICM-Norm                      | 0.4080    |\n",
    "| F1                            | 0.4900    |\n",
    "| F1-IDEOLOGICAL-INEQUALITY     | 0.4561    |\n",
    "| F1-STEREOTYPING-DOMINANCE     | 0.4858    |\n",
    "| F1-OBJECTIFICATION            | 0.4832    |\n",
    "| F1-SEXUAL-VIOLENCE            | 0.3498    |\n",
    "| F1-MISOGYNY-NON-SEXUAL-VIOLENCE | 0.4052  |\n",
    "| F1-NO                         | 0.7600    |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e7ba1b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b245f84",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "085a8817",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "360069ce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7757589",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88710fc1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "427c9598",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a71acd17",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4df2d1c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "066b87ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80cec996",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e53ca225",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8a76fee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8574f936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-01 01:04:25,411 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICM', 'ICMNorm', 'FMeasure']\n",
      "2025-09-01 01:04:25,457 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:04:25,568 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Normalized evaluation method\n",
      "2025-09-01 01:04:25,569 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:04:25,686 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:04:25,808 - pyevall.metrics.metrics - INFO -             evaluate() - Executing fmeasure evaluation method\n",
      "{\n",
      "  \"metrics\": {\n",
      "    \"ICM\": {\n",
      "      \"name\": \"Information Contrast model\",\n",
      "      \"acronym\": \"ICM\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"average\": 0.5785920013897591\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.5785920013897591\n",
      "      }\n",
      "    },\n",
      "    \"ICMNorm\": {\n",
      "      \"name\": \"Normalized Information Contrast Model\",\n",
      "      \"acronym\": \"ICM-Norm\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"average\": 0.7894338709025941\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.7894338709025941\n",
      "      }\n",
      "    },\n",
      "    \"FMeasure\": {\n",
      "      \"name\": \"F-Measure\",\n",
      "      \"acronym\": \"F1\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"classes\": {\n",
      "            \"YES\": 0.8074534161490683,\n",
      "            \"NO\": 0.8210735586481113\n",
      "          },\n",
      "          \"average\": 0.8142634873985898\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.8142634873985898\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"files\": {\n",
      "    \"predictions_task1_1.json\": {\n",
      "      \"name\": \"predictions_task1_1.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": false,\n",
      "      \"description\": \"Use parameter: report=\\\"embedded\\\"!\",\n",
      "      \"errors\": {}\n",
      "    },\n",
      "    \"EXIST2025_dev_task1_1_gold_hard.json\": {\n",
      "      \"name\": \"EXIST2025_dev_task1_1_gold_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": true,\n",
      "      \"description\": \"Use parameter: report=\\\"embedded\\\"!\",\n",
      "      \"errors\": {}\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pred_1_1tf = \"/home/luisa-fernanda/Descargas/pers/sre/src/notebooks/predictions_task1_1.json\"\n",
    "gold_1_1 = \"/home/luisa-fernanda/Descargas/pers/sre/evaluation/golds/EXIST2025_dev_task1_1_gold_hard.json\"\n",
    "\n",
    "\n",
    "params_1_1 = {\n",
    "    PyEvALLUtils.PARAM_REPORT: PyEvALLUtils.PARAM_OPTION_REPORT_DATAFRAME\n",
    "}\n",
    "report_1_1_tra = evaluator.evaluate(pred_1_1tf, gold_1_1, metrics)\n",
    "\n",
    "report_1_1_tra.print_report()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a8a334",
   "metadata": {},
   "source": [
    "## Comparativa de Modelos segun pyevall para la task 1.1\n",
    "\n",
    "| Modelo       |     ICM    | ICM-Norm |    F1   |  F1-YES  |  F1-NO  |\n",
    "|:------------:|:----------:|:--------:|:-------:|:--------:|:-------:|\n",
    "| H铆brido      | 0.3668     | 0.6835   | 0.7471  | 0.7354   | 0.7589  |\n",
    "| Transformer  | 0.5786     | 0.7894   | 0.8143  | 0.8075   | 0.8211  |\n",
    "\n",
    "En la tabla anterior se presenta una comparativa entre los modelos evaluados. El modelo **Transformer** supera al modelo **H铆brido** en todas las m茅tricas, destac谩ndose especialmente en el 铆ndice ICM-Norm y la m茅trica F1. Esto sugiere que el modelo Transformer tiene un mejor desempe帽o general en la tarea evaluada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "163dc6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-01 01:03:40,208 - pyevall.evaluation - INFO -             evaluate() - Evaluating the following metrics ['ICM', 'ICMNorm', 'FMeasure']\n",
      "2025-09-01 01:03:40,256 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:03:40,360 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM Normalized evaluation method\n",
      "2025-09-01 01:03:40,360 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:03:40,464 - pyevall.metrics.metrics - INFO -             evaluate() - Executing ICM evaluation method\n",
      "2025-09-01 01:03:40,562 - pyevall.metrics.metrics - INFO -             evaluate() - Executing fmeasure evaluation method\n",
      "{\n",
      "  \"metrics\": {\n",
      "    \"ICM\": {\n",
      "      \"name\": \"Information Contrast model\",\n",
      "      \"acronym\": \"ICM\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"average\": -2.854364098946497\n",
      "        }],\n",
      "        \"average_per_test_case\": -2.854364098946497\n",
      "      }\n",
      "    },\n",
      "    \"ICMNorm\": {\n",
      "      \"name\": \"Normalized Information Contrast Model\",\n",
      "      \"acronym\": \"ICM-Norm\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"average\": 0\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.0\n",
      "      }\n",
      "    },\n",
      "    \"FMeasure\": {\n",
      "      \"name\": \"F-Measure\",\n",
      "      \"acronym\": \"F1\",\n",
      "      \"description\": \"Coming soon!\",\n",
      "      \"status\": \"OK\",\n",
      "      \"results\": {\n",
      "        \"test_cases\": [{\n",
      "          \"name\": \"EXIST2025\",\n",
      "          \"classes\": {\n",
      "            \"JUDGEMENTAL\": 0.031746031746031744,\n",
      "            \"NO\": 0.11374407582938387,\n",
      "            \"REPORTED\": 0.14814814814814814,\n",
      "            \"DIRECT\": 0.6090712742980562\n",
      "          },\n",
      "          \"average\": 0.22567738250540498\n",
      "        }],\n",
      "        \"average_per_test_case\": 0.22567738250540498\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"files\": {\n",
      "    \"predictions_task1_2_devTransformer.json\": {\n",
      "      \"name\": \"predictions_task1_2_devTransformer.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": false,\n",
      "      \"description\": \"Use parameter: report=\\\"embedded\\\"!\",\n",
      "      \"errors\": {}\n",
      "    },\n",
      "    \"EXIST2025_dev_task1_2_gold_hard.json\": {\n",
      "      \"name\": \"EXIST2025_dev_task1_2_gold_hard.json\",\n",
      "      \"status\": \"OK\",\n",
      "      \"gold\": true,\n",
      "      \"description\": \"Use parameter: report=\\\"embedded\\\"!\",\n",
      "      \"errors\": {}\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "pred_1_2tf = \"/home/luisa-fernanda/Descargas/pers/sre/src/notebooks/predictions_task1_2_devTransformer.json\"\n",
    "\n",
    "params_1_2 = {\n",
    "    PyEvALLUtils.PARAM_HIERARCHY: TASK1_2_HIERARCHY,\n",
    "    PyEvALLUtils.PARAM_REPORT: PyEvALLUtils.PARAM_OPTION_REPORT_DATAFRAME\n",
    "}\n",
    "report_1_2_tra = evaluator.evaluate(pred_1_2tf, gold_1_2, metrics)\n",
    "\n",
    "report_1_2_tra.print_report()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b09e1e2",
   "metadata": {},
   "source": [
    "\n",
    "## Comparativa de Modelos segun pyevall para la task 1.2\n",
    "\n",
    "| Modelo       |    ICM    | ICM-Norm |   F1   | F1-DIRECT | F1-REPORTED | F1-JUDGEMENTAL | F1-NO   |\n",
    "|:------------:|:---------:|:--------:|:------:|:---------:|:-----------:|:--------------:|:-------:|\n",
    "| H铆brido      | -0.1303   | 0.4593   | 0.3946 | 0.5669    | 0.1010      | 0.1605         | 0.7502  |\n",
    "| Transformer  | -2.8544   | 0.0000   | 0.2257 | 0.6091    | 0.1481      | 0.0317         | 0.1137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a645e16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi_entorno_analisis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
